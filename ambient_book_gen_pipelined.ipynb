{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantsl/anaconda3/envs/pages/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
      "    Python  3.10.13 (you have 3.10.12)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "from LLMPromptGenerator import LLMPromptGenerator\n",
    "from GenMusicFromPrompt import GenMusicFromPrompt\n",
    "\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.models import MultiBandDiffusion\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "GROUP_WORD_COUNT = 60 #120 \n",
    "SONG_DUR_SECONDS = 30 #60 \n",
    "PREV_SONG_DUR = 2 # 4\n",
    "\n",
    "MAX_GROUP_CNT = 3 # limits the number of groups to be processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extractor = LLMPromptGenerator() # device=device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_sections(file_path, desired_section_size):\n",
    "    with open(file_path) as f: \n",
    "        book_text = f.read()\n",
    "\n",
    "    words = book_text.split()\n",
    "\n",
    "    # Calculate the total number of words\n",
    "    total_words = len(words)\n",
    "\n",
    "    # Determine the number of sections, aiming for equally sized sections\n",
    "    # Calculate the optimal number of sections to avoid a significantly shorter final section\n",
    "    optimal_num_sections = round(total_words / desired_section_size)\n",
    "\n",
    "    # Calculate the new section size to more evenly distribute words across sections\n",
    "    new_section_size = total_words // optimal_num_sections if total_words % optimal_num_sections == 0 else (total_words // optimal_num_sections) + 1\n",
    "\n",
    "    # Adjust the last section to avoid being too short\n",
    "    if total_words % new_section_size < new_section_size / 2:\n",
    "        optimal_num_sections += 1\n",
    "\n",
    "    word_sections = [' '.join(words[i:i+new_section_size]) for i in range(0, total_words, new_section_size)]\n",
    "    return word_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# book_text_loc = 'prompt_examples/fotr_gandalf_balrog.txt'\n",
    "# book_text_loc = 'prompt_examples/fotr_gandalf_balrog.txt'\n",
    "\n",
    "\n",
    "def full_pipeline(book_text_loc,\n",
    "                  extractor=None,\n",
    "                  generator=None,\n",
    "                  group_word_count=GROUP_WORD_COUNT, \n",
    "                  max_group_count=MAX_GROUP_CNT,\n",
    "                  song_dur_seconds=SONG_DUR_SECONDS, \n",
    "                  previous_song_duration=PREV_SONG_DUR,\n",
    "                  device=\"cpu\",\n",
    "                  save_file_loc=None,\n",
    "                  verbose=True,\n",
    "                  flush_extractor=True):\n",
    "    # Load in Text and Split into Sections\n",
    "    word_sections = load_word_sections(book_text_loc, group_word_count)\n",
    "\n",
    "    if max_group_count is not None and len(word_sections) > max_group_count:\n",
    "        word_sections = word_sections[:max_group_count]\n",
    "\n",
    "    if verbose:\n",
    "        print('section count:', len(word_sections))\n",
    "\n",
    "    if extractor is None:\n",
    "        if verbose:\n",
    "            print('Creating new extractor')\n",
    "        extractor = LLMPromptGenerator()\n",
    "    \n",
    "    # Extract JSON Info\n",
    "    extracted_json = extractor.extract_info(word_sections, flush=flush_extractor)\n",
    "    # Generate Prompts\n",
    "    prompts = extractor.prompts()\n",
    "    \n",
    "    print(extractor.info)\n",
    "   \n",
    "    if verbose:\n",
    "        print('Prompts:')\n",
    "        for p in prompts:\n",
    "            print(p)\n",
    "    \n",
    "    if generator is None:\n",
    "        if verbose:\n",
    "            print('Creating new generator')\n",
    "        generator = GenMusicFromPrompt(duration=song_dur_seconds, device=device, previous_song_duration=previous_song_duration)\n",
    "    \n",
    "\n",
    "    music = generator.generate_from_list(prompts, verbose=verbose, flush=True)\n",
    "    if save_file_loc is not None:\n",
    "        if os.path.isdir(save_file_loc):\n",
    "            base_name = os.path.basename(book_text_loc).split('.')[0] + '.wav'\n",
    "            save_file_loc = os.path.join(save_file_loc, base_name)\n",
    "        generator.save_audio(save_file_loc)\n",
    "    \n",
    "    return generator, prompts #, extracted_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_text_loc: prompt_examples/fotr_gandalf_balrog.txt\n",
      "section count: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantsl/anaconda3/envs/pages/lib/python3.10/site-packages/transformers/generation/utils.py:1295: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MusicGenInfo(short_term=ShortTermAttributes(tone='mystical', intensity='soft', is_crescendo=False, volume='low'), long_term=LongTermAttributes(instrumentation='orchestral', short_background_ambient_setting='mystical forest', short_music_descriptors='ethereal', pitch='C', beat='slow', is_major_key=True)), MusicGenInfo(short_term=ShortTermAttributes(tone='mellow', intensity='soft and subtle', is_crescendo=False, volume='low'), long_term=LongTermAttributes(instrumentation='piano', short_background_ambient_setting='a soft, gentle melody', short_music_descriptors='a soothing, calming atmosphere', pitch='C', beat='slow and steady', is_major_key=True)), MusicGenInfo(short_term=ShortTermAttributes(tone='mysterious', intensity='soft', is_crescendo=False, volume='low'), long_term=LongTermAttributes(instrumentation='orchestral', short_background_ambient_setting='mysterious', short_music_descriptors='ethereal', pitch='middle', beat=' steady', is_major_key=False))]\n",
      "Prompts:\n",
      "mystical forest ambient music setting orchestral instrumentals in a major key. mystical tone soft intensity and low volume\n",
      "mystical forest ambient music setting orchestral instrumentals in a major key. mellow tone soft and subtle intensity and low volume\n",
      "mystical forest ambient music setting orchestral instrumentals in a major key. mysterious tone soft intensity and low volume\n",
      "Creating new generator\n",
      "Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantsl/anaconda3/envs/pages/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1503 /   1500\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grantsl/anaconda3/envs/pages/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      " 33%|███▎      | 1/3 [01:26<02:53, 86.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1003 /   1600\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [02:51<01:25, 85.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1000 /   1600\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:15<00:00, 85.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1003 /   1600\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# book_text_loc = 'prompt_examples/wok_war.txt'\n",
    "book_text_loc = 'prompt_examples/fotr_gandalf_balrog.txt'\n",
    "\n",
    "# book_text_loc = 'prompt_examples/cith_things.txt'\n",
    "# book_text_loc = './prompt_examples/rots_obiewan_vs_anakin_pt1.txt'\n",
    "# book_text_loc = './prompt_examples/raj_romeo_stalking_pt1.txt'\n",
    "\n",
    "\n",
    "output_dir = './generated_examples_midterm/'\n",
    "print('book_text_loc:', book_text_loc)\n",
    "generator, prompts = full_pipeline(book_text_loc, extractor=extractor, save_file_loc=output_dir, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoors setting, calm tone, low intensity, piano instrumentals, C pitch\n",
      "---\n",
      "A dark and stormy night setting, Serene tone, Soft intensity, Piano instrumentals, Middle C pitch\n",
      "---\n",
      "a clear summer evening setting, serene tone, soft intensity, piano instrumentals, C major pitch\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    print(prompt)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left to work on\n",
    "\n",
    "#### Before Midterm\n",
    "* Metric for generated music - What is good?\n",
    "* Look at generation times vs quality (Facebook model - Is live generation feasible?)\n",
    "\n",
    "#### After Midterm\n",
    "* Modify the LLM class to pass in a giant text file, batch, and generate json\n",
    "* Pipeline the LLM and GenMusic class in a pipeline class\n",
    "* Prompt engineering\n",
    "* Fun: Karaoke interface \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
