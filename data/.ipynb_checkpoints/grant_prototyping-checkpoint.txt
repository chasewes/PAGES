def generate_music(model, prompt, prev_song=None, prompt_sr=32000, prev_song_overlap=2):
    if prev_song is None: # If initial song
        output = model.generate(
            progress=True, return_tokens=True, descriptions=[prompt]
        )
        initial_song = output[0]
        return initial_song
    else: # If continuation
        trim_amount = int(prev_song_overlap * prompt_sr)
        prompt_waveform = prompt_waveform[..., -trim_amount:]
        # Generate the continuation
        continued_song = model.generate_continuation(prompt_waveform,  # Add batch dimension
                                            prompt_sample_rate=prompt_sr,  # Use the generated sample rate
                                            progress=True, return_tokens=True, descriptions=[prompt])
        continued_song = continued_song[0][:, :, trim_amount:]
        combined_song = torch.cat([prev_song, continued_song], dim=-1)
        return combined_song