{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Ambient_Pipeline import Music_Gen_Pipeline\n",
    "from LLMPromptGenerator import LLMPromptGenerator\n",
    "from GenMusicFromPrompt import GenMusicFromPrompt\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class DirectLLMPromptGenerator:\n",
    "    def __init__(self, model_name=\"TheBloke/Llama-2-7b-Chat-GPTQ\"):\n",
    "        self.model_name = model_name\n",
    "        self.hf_pipeline = pipeline('text-generation', model=model_name, device_map='auto')\n",
    "        \n",
    "    def generate_llm_prompt(self, text, prompt_format=None, few_shot=None):\n",
    "        if prompt_format is None:\n",
    "            prompt_format = \"\"\"\n",
    "            TASK: \n",
    "            From the provided text, generate a prompt for a music generation model such that the generated music encapsulates \n",
    "            the mood, tone, setting, and intensity of the text and can be used as background music for the text. Remember that\n",
    "            the music generation model does not have the text as a reference, and will generate music based only on the prompt.\n",
    "            Be sure to emphasize that the music should be a background track, and keep the prompt short.\n",
    "            {}\n",
    "            TEXT: \n",
    "            {} \n",
    "            PROMPT: \n",
    "            \"\"\"\n",
    "        if few_shot is True:\n",
    "            few_shot = \"\"\"\n",
    "            Following are some example prompts to the music generation model. You can use them as inspiration to create your own prompt.\n",
    "\n",
    "            EXAMPLE PROMPT 1:\n",
    "            A grand orchestral arrangement with thunderous percussion, epic brass fanfares, and soaring strings, creating a cinematic atmosphere fit for a heroic battle.\n",
    "\n",
    "            EXAMPLE PROMPT 2:\n",
    "            drum and bass beat with intense percussions\n",
    "\n",
    "            EXAMPLE PROMPT 3:\n",
    "            Violins and synths that inspire awe at the finiteness of life and the universe.\n",
    "\n",
    "            EXAMPLE PROMPT 4:\n",
    "            A dynamic blend of hip-hop and orchestral elements, with sweeping strings and brass, evoking the vibrant energy of the city.\n",
    "            \"\"\"\n",
    "        elif few_shot is None:\n",
    "            few_shot = \"\"\n",
    "\n",
    "        return prompt_format.format(few_shot, text)\n",
    "    \n",
    "    def generate_musicgen_prompt(self, text, prompt_format=None, few_shot=None):\n",
    "        # Generate prompt for the LLM\n",
    "        llm_prompt = self.generate_llm_prompt(text, prompt_format=prompt_format, few_shot=few_shot)\n",
    "        \n",
    "        #get the output (in json format) from the LLM\n",
    "        llm_output = self.hf_pipeline(llm_prompt)\n",
    "        generated_text = llm_output[0]['generated_text']\n",
    "        \n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = DirectLLMPromptGenerator()\n",
    "# generator = GenMusicFromPrompt(device=device)\n",
    "# pipe = Music_Gen_Pipeline(extractor=extractor, generator=generator, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"evaluation/excerpts/\"\n",
    "out_dir = \"evaluation/generated_songs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayjobla/PAGES/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1295: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            TASK: \n",
      "            From the provided text, generate a prompt for a music generation model such that the generated music encapsulates \n",
      "            the mood, tone, setting, and intensity of the text and can be used as background music for the text. Remember that\n",
      "            the music generation model does not have the text as a reference, and will generate music based only on the prompt.\n",
      "            Be sure to emphasize that the music should be a background track, and keep the prompt short.\n",
      "            \n",
      "            TEXT: \n",
      "            A spray of lava from the river that melted one of the supports provided the final straw. A huge section of a collection arm broke away and fell into the lava, carrying the two Jedi with it. Still the fight continued, even as the collection tower sank slowly into the lava. And still, neither man could gain an advantage. But \n",
      "            PROMPT: \n",
      "            ðŸ”¥ðŸŒ‹ Echoes of Lava ðŸ”¥ðŸŒ‹\n",
      "            A haunting melody, born from the fiery depths of a river's wrath. The rhythm pulses with the heat of the lava, its intensity matching the intensity of the battle. As the collection tower sinks, the music swirls and churns, capturing the chaos and destruction of the scene. The melody is both ominous and hypnotic, drawing the listener into the heart of the lava river.\n",
      "\n",
      "            TASK: \n",
      "            From the provided text, generate a prompt for a music generation model such that the generated music encapsulates \n",
      "            the mood, tone, setting, and intensity of the text and can be used as background music for the text. Remember that\n",
      "            the music generation model does not have the text as a reference, and will generate music based only on the prompt.\n",
      "            Be sure to emphasize that the music should be a background track, and keep the prompt short.\n",
      "            \n",
      "            Following are some example prompts to the music generation model. You can use them as inspiration to create your own prompt.\n",
      "\n",
      "            EXAMPLE PROMPT 1:\n",
      "            A grand orchestral arrangement with thunderous percussion, epic brass fanfares, and soaring strings, creating a cinematic atmosphere fit for a heroic battle.\n",
      "\n",
      "            EXAMPLE PROMPT 2:\n",
      "            drum and bass beat with intense percussions\n",
      "\n",
      "            EXAMPLE PROMPT 3:\n",
      "            Violins and synths that inspire awe at the finiteness of life and the universe.\n",
      "\n",
      "            EXAMPLE PROMPT 4:\n",
      "            A dynamic blend of hip-hop and orchestral elements, with sweeping strings and brass, evoking the vibrant energy of the city.\n",
      "            \n",
      "            TEXT: \n",
      "            A spray of lava from the river that melted one of the supports provided the final straw. A huge section of a collection arm broke away and fell into the lava, carrying the two Jedi with it. Still the fight continued, even as the collection tower sank slowly into the lava. And still, neither man could gain an advantage. But \n",
      "            PROMPT: \n",
      "            \n",
      "            A haunting melody with a hint of mystery, evoking the dark and foreboding atmosphere of the lava river and the impending doom of the collection tower's demise. The music should build in intensity as the fight progresses, reflecting the escalating danger and the Jedi's growing exhaustion.\n",
      "\n",
      "            MUSIC GENERATION MODEL: \n",
      "            I am a text-to-music generation model trained on a large dataset of text and corresponding music. I can generate music in a variety of styles and moods, including classical, jazz, rock, and more. Please provide me with the text you would like me to use as input, and I will generate a piece of music that captures the mood, tone, setting, and intensity of the text.\n"
     ]
    }
   ],
   "source": [
    "test_audio_file = \"evaluation/excerpts/rots.txt\"\n",
    "\n",
    "with open(test_audio_file) as f: \n",
    "    text = f.read()\n",
    "text = ' '.join(text.split()[:60])  # limit to 60 words\n",
    "\n",
    "prompt = extractor.generate_musicgen_prompt(text)\n",
    "prompt_fs = extractor.generate_musicgen_prompt(text, few_shot=True)\n",
    "\n",
    "print(prompt)\n",
    "print(prompt_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayjobla/PAGES/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1295: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            TASK: \n",
      "            From the provided text, generate a prompt for a music generation model such that the generated music encapsulates \n",
      "            the mood, tone, setting, and intensity of the text and can be used as background music for the text. Remember that\n",
      "            the music generation model does not have the text as a reference, and will generate music based only on the prompt.\n",
      "            Be sure to emphasize that the music should be a background track, and keep the prompt short.\n",
      "            \n",
      "            TEXT: \n",
      "            A spray of lava from the river that melted one of the supports provided the final straw. A huge section of a collection arm broke away and fell into the lava, carrying the two Jedi with it. Still the fight continued, even as the collection tower sank slowly into the lava. And still, neither man could gain an advantage. But \n",
      "            PROMPT: \n",
      "            ðŸ”¥ðŸŒ‹ Echoes of Lava ðŸ”¥ðŸŒ‹\n",
      "            A haunting melody, born from the fiery depths of a river's wrath. The rhythm pulses with the heat of the lava, its intensity matching the intensity of the battle. As the collection tower sinks, the music swirls and churns, capturing the chaos and destruction of the scene. The melody is both ominous and hypnotic, drawing the listener into the heart of the lava river.\n"
     ]
    }
   ],
   "source": [
    "for i, filepath in enumerate(os.listdir(text_dir)):\n",
    "    if not filepath.endswith(\".txt\"):   # Only grab text files\n",
    "        continue\n",
    "\n",
    "    with open(f\"{text_dir}{filepath}\") as f: \n",
    "        text = f.read()\n",
    "    text = ' '.join(text.split()[:60])\n",
    "\n",
    "    # Load the text section and generate the MusicGen prompt\n",
    "    # text = pipe.text_to_sections(f\"{text_dir}{filepath}\")[0]        # Use to only take first section\n",
    "    # text = pipe.load_txt(f\"{text_dir}{filepath}\")                   # Use to input entire excerpt\n",
    "                                  # Only take first 60 words\n",
    "    musicgen_prompt = extractor.generate_musicgen_prompt(text)    # Generate MusicGen prompt\n",
    "    print(musicgen_prompt)\n",
    "    break\n",
    "\n",
    "    # Generate song\n",
    "    pipe.generator.generate(musicgen_prompt, duration=10, prev_song_duration=0, song=None)\n",
    "    pipe.generator.save_audio(f\"{out_dir}{filepath.split('.')[0]}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
