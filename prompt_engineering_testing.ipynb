{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, parse_obj_as, Field, constr\n",
    "from lmformatenforcer import JsonSchemaParser\n",
    "from lmformatenforcer.integrations.transformers import build_transformers_prefix_allowed_tokens_fn\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# texts = ['Harry looked down in time to see a tiny, wrinkled, newborn bird poke its head out of the ashes. It was quite as ugly as the old one. \"\\'It\\'s a shame you had to see him on a burning day,\\' said Dumbledore, seating himself behind his desk. \"\\'He\\'s really very handsome most of the time, wonderful red and gold plumage—facinating creatures, Phoenixes.', \n",
    "#          ' They can carry immensely heavy loads, their tears have healing powers, and they make highly faithful pets. In the shock of forks catching fire, Harry had forgotten what he was there for, but it all came back to him as Dumbledore settled himself in the high-backed chair behind the desk, and fixed Harry with his penetrating light blue stare.']\n",
    "\n",
    "chunks = [\n",
    "    {'timestamp': [0.0, 24.52], \n",
    "    'text': ' The dark figure streaming with fire raced towards them. The orcs yelled and poured over the stone gangways. Then Boromir raised his horn and blew. Loud the challenge rang and bellowed, like the shout of many throats under the cavernous roof. For a moment the orcs quailed and the fiery shadow halted. Then the echoes died as suddenly as a flame blown out by a dark wind, and the enemy advanced again.',\n",
    "    'duration': 24.52}, \n",
    "    {'timestamp': [24.52, 47.64], \n",
    "    'text': 'Over the bridge! cried Gandalf, recalling his strength. ‘Fly! This is a foe beyond any of you. I must hold the narrow way. Fly!’ Aragorn and Boromir did not heed the command, but still held their ground, side by side, behind Gandalf at the far end of the bridge. The others halted just within the doorway at the halls end, and turned, unable to leave their leader to face the enemy alone.',\n",
    "    'duration': 23.12\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MusicGenInfo(BaseModel):    \n",
    "    tone: str\n",
    "    intensity: str\n",
    "    setting: str\n",
    "    tempo: str\n",
    "    musical_instrument: str\n",
    "    is_major_key: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLMPromptGenerator:\n",
    "    def __init__(self, model_name=\"TheBloke/Llama-2-7b-Chat-GPTQ\"): # device=\"cpu\"\n",
    "        self.model_name = model_name\n",
    "        self.hf_pipeline = pipeline('text-generation', model=model_name, device_map='auto') # device=device)\n",
    "        self.info = []\n",
    "        self.long_term_prompt = None\n",
    "\n",
    "        self.major_key = None\n",
    "        self.instrument = None\n",
    "        \n",
    "        \n",
    "    def generate_llm_prompt(self, text, prompt=None):\n",
    "        \n",
    "        if prompt is None:\n",
    "            prompt = \"\"\"\n",
    "            TEXT: {} \n",
    "            \n",
    "            TASK: In JSON Format, A piece music generated as background ambience for the above text would have these qualities:\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #incorporate json format into prompt and return\n",
    "        return prompt.format(text)\n",
    "        \n",
    "    def extract_json_from_llm_output(self, llm_output):\n",
    "        pattern = r'\\{.*?\\}'  # Non-greedy match for JSON-like objects\n",
    "        matches = re.findall(pattern, llm_output, re.DOTALL)\n",
    "\n",
    "        if not matches:\n",
    "            return {}  # Return an empty dict if no matches are found\n",
    "\n",
    "        # Initialize a variable to keep track of the longest JSON match\n",
    "        longest_match = \"\"\n",
    "        for match in matches:\n",
    "            # Update longest_match if the current match is longer\n",
    "            if len(match) > len(longest_match):\n",
    "                try:\n",
    "                    # Check if the current match is a valid JSON\n",
    "                    json.loads(match)\n",
    "                    longest_match = match\n",
    "                except json.JSONDecodeError:\n",
    "                    # If not a valid JSON, continue to the next match\n",
    "                    continue\n",
    "\n",
    "        # Attempt to parse the longest match as JSON, if it exists\n",
    "        if longest_match:\n",
    "            try:\n",
    "                json_obj = json.loads(longest_match)\n",
    "                return json_obj\n",
    "            except json.JSONDecodeError:\n",
    "                # Should not happen, as we've already tested with json.loads\n",
    "                return {}\n",
    "        else:\n",
    "            return {}  # Return an empty dict if no valid JSON objects were found\n",
    "\n",
    "\n",
    "    \n",
    "    def generate_musicgen_prompt(self, text, music_gen_info=MusicGenInfo, prompt=None, flush=False):\n",
    "        # Generate prompt for the LLM\n",
    "        llm_prompt = self.generate_llm_prompt(text, prompt=prompt)\n",
    "        \n",
    "        #prime the model to generate the proper json format\n",
    "        parser = JsonSchemaParser(music_gen_info.schema())\n",
    "        prefix_function = build_transformers_prefix_allowed_tokens_fn(self.hf_pipeline.tokenizer, parser)\n",
    "        \n",
    "        #get the output (in json format) from the LLM\n",
    "        llm_output = self.hf_pipeline(llm_prompt, prefix_allowed_tokens_fn=prefix_function)\n",
    "        generated_text = llm_output[0]['generated_text']\n",
    "        \n",
    "        #extract the json object from the generated_text and convert it to a dict.\n",
    "        music_attributes = self.extract_json_from_llm_output(generated_text)\n",
    "        \n",
    "        #set/reset the long term attributes\n",
    "        if flush or self.major_key is None: \n",
    "            self.major_key = music_attributes['is_major_key']\n",
    "            self.instrument = music_attributes['musical_instrument']\n",
    "\n",
    "        #create the prompt using fstring\n",
    "        prompt = (f\"Ambient Background music with a {music_attributes['tone']} tone and {music_attributes['intensity']} intensity, \"\n",
    "          f\"using {self.instrument} instrumentation to create a {music_attributes['setting']} setting. \"\n",
    "          f\"The piece moves at a {music_attributes['tempo']} pace, \"\n",
    "          f\"{'in a major key' if self.major_key else 'in a minor key'}, \"\n",
    "          \"evoking an immersive atmosphere.\")\n",
    "        \n",
    "        return prompt\n",
    "        \n",
    "    def generate_from_chunks(self, chunks, music_gen_info=MusicGenInfo, prompt=None):\n",
    "        prompts = []\n",
    "        \n",
    "        flush = False\n",
    "        for chunk in chunks: \n",
    "            #some logic to determine when to flush could go here. \n",
    "            \n",
    "            #generate the prompt and add it to the list\n",
    "            prompts.append(self.generate_musicgen_prompt(chunk['text'], flush=flush))\n",
    "            \n",
    "            \n",
    "        return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-chasewes/.conda/envs/mcmc/lib/python3.8/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extractor = LLMPromptGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-chasewes/.conda/envs/mcmc/lib/python3.8/site-packages/transformers/generation/utils.py:1197: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ambient Background music with a dark tone and loud intensity, using orchestral to create a cave setting. The piece moves at a 100 pace, in a minor key, evoking an immersive atmosphere.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = extractor.generate_musicgen_prompt(chunks[0]['text'])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-chasewes/.conda/envs/mcmc/lib/python3.8/site-packages/transformers/generation/utils.py:1197: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambient Background music with a ominous tone and loud intensity, using dark_figure_streaming_with_fire_raced_towards_them to create a cavernous setting. The piece moves at a fast pace, in a minor key, evoking an immersive atmosphere.\n",
      "Ambient Background music with a serious tone and soft intensity, using dark_figure_streaming_with_fire_raced_towards_them to create a outdoor setting. The piece moves at a moderate pace, in a minor key, evoking an immersive atmosphere.\n"
     ]
    }
   ],
   "source": [
    "all_prompts = extractor.generate_from_chunks(chunks)\n",
    "for prompt in all_prompts:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcmc",
   "language": "python",
   "name": "mcmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
